{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54ff292f-d8b1-4f52-ab0f-dfd5fc5263af",
   "metadata": {},
   "source": [
    "# Inport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dace882f-6e16-4310-999f-8583f0ca2daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mas/anaconda3/envs/SelfRecon/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dataset.dataset import getDatasetAndLoader\n",
    "from model import getOptNet\n",
    "from pyhocon import ConfigFactory,HOCONConverter\n",
    "import argparse\n",
    "import trimesh\n",
    "import os\n",
    "import os.path as osp\n",
    "from MCAcc import Seg3dLossless\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec93d8-29f4-49f3-b6d1-998d09750967",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b25740c3-8431-4552-8705-b1deade26998",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root=\"/mnt/data/study/computer_vision/selfrecon/female-3-casual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ffc405-0d28-49e1-9a95-ba2043d26b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='neu video body rec')\n",
    "parser.add_argument('--gpu-ids',default=[0],nargs='+',type=int,metavar='IDs',\n",
    "\t\t\t\t\thelp='gpu ids') # metavar: Alternate display name for the argument as shown in help \n",
    "parser.add_argument('--conf',default=\"config.conf\",metavar='M',\n",
    "\t\t\t\t\thelp='config file')\n",
    "parser.add_argument('--data',default=data_root,metavar='M',\n",
    "\t\t\t\t\thelp='data root')\n",
    "parser.add_argument('--model',default=None,metavar='M',\n",
    "\t\t\t\t\thelp='pretrained scene model')\n",
    "parser.add_argument('--model-rm-prefix',nargs='+',type=str,metavar='rm prefix', help='rm model prefix')\n",
    "parser.add_argument('--sdf-model',default=None,metavar='M',\n",
    "\t\t\t\t\thelp='substitute sdf model')\n",
    "parser.add_argument('--save-folder',default=\"result\",metavar='M',help='save folder')\n",
    "args = parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc946f2c-baea-412d-a13d-96566bd80138",
   "metadata": {},
   "outputs": [],
   "source": [
    "config=ConfigFactory.parse_file(args.conf)\n",
    "if len(args.gpu_ids):\n",
    "\tdevice=torch.device(args.gpu_ids[0])\n",
    "else:\n",
    "\tdevice=torch.device(0)\n",
    "data_root=args.data\n",
    "if args.save_folder is None:\n",
    "\tprint('please set save-folder...')\n",
    "\tassert(False)\n",
    "\n",
    "save_root=osp.join(data_root,args.save_folder)\n",
    "debug_root=osp.join(save_root,'debug')\n",
    "os.makedirs(save_root,exist_ok=True)\n",
    "os.makedirs(debug_root,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bbbd082-77eb-4d6a-885a-db1e9957daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#point render\n",
    "resolutions={'coarse':\n",
    "[\n",
    "\t(14+1, 20+1, 8+1),\n",
    "\t(28+1, 40+1, 16+1),\n",
    "\t(56+1, 80+1, 32+1),\n",
    "\t(112+1, 160+1, 64+1),\n",
    "\t(224+1, 320+1, 128+1),\n",
    "],\n",
    "'medium':\n",
    "[\n",
    "\t(18+1, 24+1, 12+1),\n",
    "\t(36+1, 48+1, 24+1),\n",
    "\t(72+1, 96+1, 48+1),\n",
    "\t(144+1, 192+1, 96+1),\n",
    "\t(288+1, 384+1, 192+1),\n",
    "],\n",
    "'fine':\n",
    "[\n",
    "\t(20+1, 26+1, 14+1),\n",
    "\t(40+1, 52+1, 28+1),\n",
    "\t(80+1, 104+1, 56+1),\n",
    "\t(160+1, 208+1, 112+1),\n",
    "\t(320+1, 416+1, 224+1),\n",
    "]\n",
    "}\n",
    "\n",
    "resolutions_higher = [\n",
    "\t(32+1, 32+1, 32+1),\n",
    "\t(64+1, 64+1, 64+1),\n",
    "\t(128+1, 128+1, 128+1),\n",
    "\t(256+1, 256+1, 256+1),\n",
    "\t(512+1, 512+1, 512+1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167b8941-1ab0-4578-8fcd-3ea39eafad66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene data use female smpl\n"
     ]
    }
   ],
   "source": [
    "# save the config file\n",
    "with open(osp.join(save_root,'config.conf'),'w') as ff:\n",
    "\tff.write(HOCONConverter.convert(config,'hocon'))\n",
    "condlen={'deformer':config.get_int('mlp_deformer.condlen'),'renderer':config.get_int('render_net.condlen')}\n",
    "batch_size=config.get_int('train.coarse.point_render.batch_size')\n",
    "dataset,dataloader=getDatasetAndLoader(data_root,condlen,batch_size,\n",
    "\t\t\t\t\t\tconfig.get_bool('train.shuffle'),config.get_int('train.num_workers'),\n",
    "\t\t\t\t\t\tconfig.get_bool('train.opt_pose'),config.get_bool('train.opt_trans'),config.get_config('train.opt_camera'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb998e6c-e382-49d1-b496-56e14a95dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmins=None\n",
    "bmaxs=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "739104f8-cb6e-4387-8034-71580049aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.get_int('train.initial_iters')<=0:\n",
    "\tuse_initial_sdf=True\n",
    "else:\n",
    "\tuse_initial_sdf=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad3693f1-7801-45c9-8741-7df7e80b8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memo: at this line, GPU memory usage: 224MB/8GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bb68393-fee4-468d-add0-020a8bff3130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mas/anaconda3/envs/SelfRecon/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811806235/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.29 GiB (GPU 0; 7.80 GiB total capacity; 5.22 GiB already allocated; 530.44 MiB free; 5.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optNet,sdf_initialized\u001b[38;5;241m=\u001b[39m\u001b[43mgetOptNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbmins\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbmaxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresolutions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoarse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_initial_sdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/proj/study/computer_vision/SelfReconCode/model/network.py:850\u001b[0m, in \u001b[0;36mgetOptNet\u001b[0;34m(dataset, N, bmins, bmaxs, resolutions, device, conf, use_initial_sdf, use_initial_skinner)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    848\u001b[0m \t\u001b[38;5;66;03m# initilize initPose to A pose to save volume space\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \tinitPose\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(utils\u001b[38;5;241m.\u001b[39msmpl_tmp_Apose(init_pose_type))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m24\u001b[39m,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 850\u001b[0m \tskinner,tmpBodyVs,tmpBodyFs\u001b[38;5;241m=\u001b[39m\u001b[43minitialLBSkinner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgender\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43minitPose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbmins\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbmaxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m \ttorch\u001b[38;5;241m.\u001b[39msave({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mws\u001b[39m\u001b[38;5;124m'\u001b[39m:skinner\u001b[38;5;241m.\u001b[39mws,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbmins\u001b[39m\u001b[38;5;124m'\u001b[39m:skinner\u001b[38;5;241m.\u001b[39mb_min,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbmaxs\u001b[39m\u001b[38;5;124m'\u001b[39m:skinner\u001b[38;5;241m.\u001b[39mb_max,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJs\u001b[39m\u001b[38;5;124m'\u001b[39m:skinner\u001b[38;5;241m.\u001b[39mJs,\n\u001b[1;32m    852\u001b[0m \t\t\t\t\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparents\u001b[39m\u001b[38;5;124m'\u001b[39m:skinner\u001b[38;5;241m.\u001b[39mparents,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit_pose\u001b[39m\u001b[38;5;124m'\u001b[39m:skinner\u001b[38;5;241m.\u001b[39minit_pose,\n\u001b[1;32m    853\u001b[0m \t\t\t\t\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmpBodyVs\u001b[39m\u001b[38;5;124m'\u001b[39m:tmpBodyVs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmpBodyFs\u001b[39m\u001b[38;5;124m'\u001b[39m:tmpBodyFs},\n\u001b[1;32m    854\u001b[0m \t\t\t\tskinner_pth_name)\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m#use False: weight norm can influence weight initialization, can not produce small weights as initialization\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# deformer=MLPTranslator(dataset.conds[dataset.cond_ns.index('deformer')].shape[-1],conf.get_int('mlp_deformer.multires'),False)\u001b[39;00m\n",
      "File \u001b[0;32m~/proj/study/computer_vision/SelfReconCode/model/Deformer.py:294\u001b[0m, in \u001b[0;36minitialLBSkinner\u001b[0;34m(gender, shape, pose, resolution, bmins, bmaxs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \tbmins\u001b[38;5;241m=\u001b[39m(verts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m-\u001b[39mmargin)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    293\u001b[0m \tbmaxs\u001b[38;5;241m=\u001b[39m(verts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m+\u001b[39mmargin)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m--> 294\u001b[0m ws\u001b[38;5;241m=\u001b[39m\u001b[43mcompute_lbswField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbmins\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbmaxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6890\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43msmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6890\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mmean_neighbor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msmooth_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LBSkinner(ws,bmins,bmaxs,Js,smpl\u001b[38;5;241m.\u001b[39mparents,init_pose\u001b[38;5;241m=\u001b[39mpose,align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),verts\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m6890\u001b[39m,\u001b[38;5;241m3\u001b[39m),torch\u001b[38;5;241m.\u001b[39mtensor(smpl\u001b[38;5;241m.\u001b[39mfaces,dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong,device\u001b[38;5;241m=\u001b[39mverts\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/proj/study/computer_vision/SelfReconCode/model/Deformer.py:269\u001b[0m, in \u001b[0;36mcompute_lbswField\u001b[0;34m(bmins, bmaxs, resolutions, smpl_verts, smpl_ws, align_corners, mean_neighbor, smooth_times)\u001b[0m\n\u001b[1;32m    265\u001b[0m fws\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind,tmp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(torch\u001b[38;5;241m.\u001b[39msplit(coords2D,\u001b[38;5;241m50000\u001b[39m)):\n\u001b[1;32m    267\u001b[0m \t\u001b[38;5;66;03m# if ind/10==0:\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \t\u001b[38;5;66;03m# \tprint(ind)\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m \tdists,indices\u001b[38;5;241m=\u001b[39m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43msmpl_verts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtopk(mean_neighbor,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,largest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    270\u001b[0m \tdists\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mclamp(dists,\u001b[38;5;241m0.0001\u001b[39m,\u001b[38;5;241m1.\u001b[39m)\n\u001b[1;32m    271\u001b[0m \tws\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39mdists\n",
      "File \u001b[0;32m~/anaconda3/envs/SelfRecon/lib/python3.8/site-packages/torch/_tensor.py:442\u001b[0m, in \u001b[0;36mTensor.norm\u001b[0;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39mnorm, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, p\u001b[38;5;241m=\u001b[39mp, dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39mkeepdim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SelfRecon/lib/python3.8/site-packages/torch/functional.py:1442\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     _dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(ndim))\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrobenius_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mfrobenius_norm(\u001b[38;5;28minput\u001b[39m, _dim, keepdim\u001b[38;5;241m=\u001b[39mkeepdim, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.29 GiB (GPU 0; 7.80 GiB total capacity; 5.22 GiB already allocated; 530.44 MiB free; 5.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "optNet,sdf_initialized=getOptNet(dataset,batch_size,bmins,bmaxs,resolutions['coarse'],device,config,use_initial_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82746755-a8fa-42aa-bf99-a24631bd680e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optNet,dataloader\u001b[38;5;241m=\u001b[39mutils\u001b[38;5;241m.\u001b[39mset_hierarchical_config(config,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoarse\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[43moptNet\u001b[49m,dataloader,resolutions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoarse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optNet' is not defined"
     ]
    }
   ],
   "source": [
    "optNet,dataloader=utils.set_hierarchical_config(config,'coarse',optNet,dataloader,resolutions['coarse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f15500a-9551-4e9e-b597-b7c7ac809c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SelfRecon",
   "language": "python",
   "name": "selfrecon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
